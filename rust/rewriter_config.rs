// This file is generated by rust-protobuf 2.22.0. Do not edit
// @generated

// https://github.com/rust-lang/rust-clippy/issues/702
#![allow(unknown_lints)]
#![allow(clippy::all)]

#![allow(unused_attributes)]
#![rustfmt::skip]

#![allow(box_pointers)]
#![allow(dead_code)]
#![allow(missing_docs)]
#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(trivial_casts)]
#![allow(unused_imports)]
#![allow(unused_results)]
//! Generated file from `tensorflow/core/protobuf/rewriter_config.proto`

/// Generated files are compatible only with the same version
/// of protobuf runtime.
// const _PROTOBUF_VERSION_CHECK: () = ::protobuf::VERSION_2_22_0;

#[derive(PartialEq,Clone,Default)]
pub struct AutoParallelOptions {
    // message fields
    pub enable: bool,
    pub num_replicas: i32,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a AutoParallelOptions {
    fn default() -> &'a AutoParallelOptions {
        <AutoParallelOptions as ::protobuf::Message>::default_instance()
    }
}

impl AutoParallelOptions {
    pub fn new() -> AutoParallelOptions {
        ::std::default::Default::default()
    }

    // bool enable = 1;


    pub fn get_enable(&self) -> bool {
        self.enable
    }
    pub fn clear_enable(&mut self) {
        self.enable = false;
    }

    // Param is passed by value, moved
    pub fn set_enable(&mut self, v: bool) {
        self.enable = v;
    }

    // int32 num_replicas = 2;


    pub fn get_num_replicas(&self) -> i32 {
        self.num_replicas
    }
    pub fn clear_num_replicas(&mut self) {
        self.num_replicas = 0;
    }

    // Param is passed by value, moved
    pub fn set_num_replicas(&mut self, v: i32) {
        self.num_replicas = v;
    }
}

impl ::protobuf::Message for AutoParallelOptions {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.enable = tmp;
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.num_replicas = tmp;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.enable != false {
            my_size += 2;
        }
        if self.num_replicas != 0 {
            my_size += ::protobuf::rt::value_size(2, self.num_replicas, ::protobuf::wire_format::WireTypeVarint);
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.enable != false {
            os.write_bool(1, self.enable)?;
        }
        if self.num_replicas != 0 {
            os.write_int32(2, self.num_replicas)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> AutoParallelOptions {
        AutoParallelOptions::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "enable",
                |m: &AutoParallelOptions| { &m.enable },
                |m: &mut AutoParallelOptions| { &mut m.enable },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "num_replicas",
                |m: &AutoParallelOptions| { &m.num_replicas },
                |m: &mut AutoParallelOptions| { &mut m.num_replicas },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<AutoParallelOptions>(
                "AutoParallelOptions",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static AutoParallelOptions {
        static instance: ::protobuf::rt::LazyV2<AutoParallelOptions> = ::protobuf::rt::LazyV2::INIT;
        instance.get(AutoParallelOptions::new)
    }
}

impl ::protobuf::Clear for AutoParallelOptions {
    fn clear(&mut self) {
        self.enable = false;
        self.num_replicas = 0;
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for AutoParallelOptions {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for AutoParallelOptions {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct ScopedAllocatorOptions {
    // message fields
    pub enable_op: ::protobuf::RepeatedField<::std::string::String>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a ScopedAllocatorOptions {
    fn default() -> &'a ScopedAllocatorOptions {
        <ScopedAllocatorOptions as ::protobuf::Message>::default_instance()
    }
}

impl ScopedAllocatorOptions {
    pub fn new() -> ScopedAllocatorOptions {
        ::std::default::Default::default()
    }

    // repeated string enable_op = 1;


    pub fn get_enable_op(&self) -> &[::std::string::String] {
        &self.enable_op
    }
    pub fn clear_enable_op(&mut self) {
        self.enable_op.clear();
    }

    // Param is passed by value, moved
    pub fn set_enable_op(&mut self, v: ::protobuf::RepeatedField<::std::string::String>) {
        self.enable_op = v;
    }

    // Mutable pointer to the field.
    pub fn mut_enable_op(&mut self) -> &mut ::protobuf::RepeatedField<::std::string::String> {
        &mut self.enable_op
    }

    // Take field
    pub fn take_enable_op(&mut self) -> ::protobuf::RepeatedField<::std::string::String> {
        ::std::mem::replace(&mut self.enable_op, ::protobuf::RepeatedField::new())
    }
}

impl ::protobuf::Message for ScopedAllocatorOptions {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_repeated_string_into(wire_type, is, &mut self.enable_op)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        for value in &self.enable_op {
            my_size += ::protobuf::rt::string_size(1, &value);
        };
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        for v in &self.enable_op {
            os.write_string(1, &v)?;
        };
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> ScopedAllocatorOptions {
        ScopedAllocatorOptions::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "enable_op",
                |m: &ScopedAllocatorOptions| { &m.enable_op },
                |m: &mut ScopedAllocatorOptions| { &mut m.enable_op },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<ScopedAllocatorOptions>(
                "ScopedAllocatorOptions",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static ScopedAllocatorOptions {
        static instance: ::protobuf::rt::LazyV2<ScopedAllocatorOptions> = ::protobuf::rt::LazyV2::INIT;
        instance.get(ScopedAllocatorOptions::new)
    }
}

impl ::protobuf::Clear for ScopedAllocatorOptions {
    fn clear(&mut self) {
        self.enable_op.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for ScopedAllocatorOptions {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for ScopedAllocatorOptions {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RewriterConfig {
    // message fields
    pub cpu_layout_conversion: RewriterConfig_CpuLayout,
    pub layout_optimizer: RewriterConfig_Toggle,
    pub constant_folding: RewriterConfig_Toggle,
    pub shape_optimization: RewriterConfig_Toggle,
    pub remapping: RewriterConfig_Toggle,
    pub common_subgraph_elimination: RewriterConfig_Toggle,
    pub arithmetic_optimization: RewriterConfig_Toggle,
    pub dependency_optimization: RewriterConfig_Toggle,
    pub loop_optimization: RewriterConfig_Toggle,
    pub function_optimization: RewriterConfig_Toggle,
    pub debug_stripper: RewriterConfig_Toggle,
    pub disable_model_pruning: bool,
    pub scoped_allocator_optimization: RewriterConfig_Toggle,
    pub pin_to_host_optimization: RewriterConfig_Toggle,
    pub implementation_selector: RewriterConfig_Toggle,
    pub auto_mixed_precision: RewriterConfig_Toggle,
    pub auto_mixed_precision_mkl: RewriterConfig_Toggle,
    pub disable_meta_optimizer: bool,
    pub meta_optimizer_iterations: RewriterConfig_NumIterationsType,
    pub min_graph_nodes: i32,
    pub experimental_disable_compressed_tensor_optimization: bool,
    pub memory_optimization: RewriterConfig_MemOptType,
    pub memory_optimizer_target_node_name_scope: ::std::string::String,
    pub meta_optimizer_timeout_ms: i64,
    pub auto_parallel: ::protobuf::SingularPtrField<AutoParallelOptions>,
    pub fail_on_optimizer_errors: bool,
    pub scoped_allocator_opts: ::protobuf::SingularPtrField<ScopedAllocatorOptions>,
    pub optimizers: ::protobuf::RepeatedField<::std::string::String>,
    pub custom_optimizers: ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer>,
    pub inter_optimizer_verifier_config: ::protobuf::SingularPtrField<super::verifier_config::VerifierConfig>,
    pub post_optimization_verifier_config: ::protobuf::SingularPtrField<super::verifier_config::VerifierConfig>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RewriterConfig {
    fn default() -> &'a RewriterConfig {
        <RewriterConfig as ::protobuf::Message>::default_instance()
    }
}

impl RewriterConfig {
    pub fn new() -> RewriterConfig {
        ::std::default::Default::default()
    }

    // .tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;


    pub fn get_cpu_layout_conversion(&self) -> RewriterConfig_CpuLayout {
        self.cpu_layout_conversion
    }
    pub fn clear_cpu_layout_conversion(&mut self) {
        self.cpu_layout_conversion = RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU;
    }

    // Param is passed by value, moved
    pub fn set_cpu_layout_conversion(&mut self, v: RewriterConfig_CpuLayout) {
        self.cpu_layout_conversion = v;
    }

    // .tensorflow.RewriterConfig.Toggle layout_optimizer = 1;


    pub fn get_layout_optimizer(&self) -> RewriterConfig_Toggle {
        self.layout_optimizer
    }
    pub fn clear_layout_optimizer(&mut self) {
        self.layout_optimizer = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_layout_optimizer(&mut self, v: RewriterConfig_Toggle) {
        self.layout_optimizer = v;
    }

    // .tensorflow.RewriterConfig.Toggle constant_folding = 3;


    pub fn get_constant_folding(&self) -> RewriterConfig_Toggle {
        self.constant_folding
    }
    pub fn clear_constant_folding(&mut self) {
        self.constant_folding = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_constant_folding(&mut self, v: RewriterConfig_Toggle) {
        self.constant_folding = v;
    }

    // .tensorflow.RewriterConfig.Toggle shape_optimization = 13;


    pub fn get_shape_optimization(&self) -> RewriterConfig_Toggle {
        self.shape_optimization
    }
    pub fn clear_shape_optimization(&mut self) {
        self.shape_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_shape_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.shape_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle remapping = 14;


    pub fn get_remapping(&self) -> RewriterConfig_Toggle {
        self.remapping
    }
    pub fn clear_remapping(&mut self) {
        self.remapping = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_remapping(&mut self, v: RewriterConfig_Toggle) {
        self.remapping = v;
    }

    // .tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;


    pub fn get_common_subgraph_elimination(&self) -> RewriterConfig_Toggle {
        self.common_subgraph_elimination
    }
    pub fn clear_common_subgraph_elimination(&mut self) {
        self.common_subgraph_elimination = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_common_subgraph_elimination(&mut self, v: RewriterConfig_Toggle) {
        self.common_subgraph_elimination = v;
    }

    // .tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;


    pub fn get_arithmetic_optimization(&self) -> RewriterConfig_Toggle {
        self.arithmetic_optimization
    }
    pub fn clear_arithmetic_optimization(&mut self) {
        self.arithmetic_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_arithmetic_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.arithmetic_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle dependency_optimization = 8;


    pub fn get_dependency_optimization(&self) -> RewriterConfig_Toggle {
        self.dependency_optimization
    }
    pub fn clear_dependency_optimization(&mut self) {
        self.dependency_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_dependency_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.dependency_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle loop_optimization = 9;


    pub fn get_loop_optimization(&self) -> RewriterConfig_Toggle {
        self.loop_optimization
    }
    pub fn clear_loop_optimization(&mut self) {
        self.loop_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_loop_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.loop_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle function_optimization = 10;


    pub fn get_function_optimization(&self) -> RewriterConfig_Toggle {
        self.function_optimization
    }
    pub fn clear_function_optimization(&mut self) {
        self.function_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_function_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.function_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle debug_stripper = 11;


    pub fn get_debug_stripper(&self) -> RewriterConfig_Toggle {
        self.debug_stripper
    }
    pub fn clear_debug_stripper(&mut self) {
        self.debug_stripper = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_debug_stripper(&mut self, v: RewriterConfig_Toggle) {
        self.debug_stripper = v;
    }

    // bool disable_model_pruning = 2;


    pub fn get_disable_model_pruning(&self) -> bool {
        self.disable_model_pruning
    }
    pub fn clear_disable_model_pruning(&mut self) {
        self.disable_model_pruning = false;
    }

    // Param is passed by value, moved
    pub fn set_disable_model_pruning(&mut self, v: bool) {
        self.disable_model_pruning = v;
    }

    // .tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;


    pub fn get_scoped_allocator_optimization(&self) -> RewriterConfig_Toggle {
        self.scoped_allocator_optimization
    }
    pub fn clear_scoped_allocator_optimization(&mut self) {
        self.scoped_allocator_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_scoped_allocator_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.scoped_allocator_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;


    pub fn get_pin_to_host_optimization(&self) -> RewriterConfig_Toggle {
        self.pin_to_host_optimization
    }
    pub fn clear_pin_to_host_optimization(&mut self) {
        self.pin_to_host_optimization = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_pin_to_host_optimization(&mut self, v: RewriterConfig_Toggle) {
        self.pin_to_host_optimization = v;
    }

    // .tensorflow.RewriterConfig.Toggle implementation_selector = 22;


    pub fn get_implementation_selector(&self) -> RewriterConfig_Toggle {
        self.implementation_selector
    }
    pub fn clear_implementation_selector(&mut self) {
        self.implementation_selector = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_implementation_selector(&mut self, v: RewriterConfig_Toggle) {
        self.implementation_selector = v;
    }

    // .tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;


    pub fn get_auto_mixed_precision(&self) -> RewriterConfig_Toggle {
        self.auto_mixed_precision
    }
    pub fn clear_auto_mixed_precision(&mut self) {
        self.auto_mixed_precision = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_auto_mixed_precision(&mut self, v: RewriterConfig_Toggle) {
        self.auto_mixed_precision = v;
    }

    // .tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;


    pub fn get_auto_mixed_precision_mkl(&self) -> RewriterConfig_Toggle {
        self.auto_mixed_precision_mkl
    }
    pub fn clear_auto_mixed_precision_mkl(&mut self) {
        self.auto_mixed_precision_mkl = RewriterConfig_Toggle::DEFAULT;
    }

    // Param is passed by value, moved
    pub fn set_auto_mixed_precision_mkl(&mut self, v: RewriterConfig_Toggle) {
        self.auto_mixed_precision_mkl = v;
    }

    // bool disable_meta_optimizer = 19;


    pub fn get_disable_meta_optimizer(&self) -> bool {
        self.disable_meta_optimizer
    }
    pub fn clear_disable_meta_optimizer(&mut self) {
        self.disable_meta_optimizer = false;
    }

    // Param is passed by value, moved
    pub fn set_disable_meta_optimizer(&mut self, v: bool) {
        self.disable_meta_optimizer = v;
    }

    // .tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;


    pub fn get_meta_optimizer_iterations(&self) -> RewriterConfig_NumIterationsType {
        self.meta_optimizer_iterations
    }
    pub fn clear_meta_optimizer_iterations(&mut self) {
        self.meta_optimizer_iterations = RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS;
    }

    // Param is passed by value, moved
    pub fn set_meta_optimizer_iterations(&mut self, v: RewriterConfig_NumIterationsType) {
        self.meta_optimizer_iterations = v;
    }

    // int32 min_graph_nodes = 17;


    pub fn get_min_graph_nodes(&self) -> i32 {
        self.min_graph_nodes
    }
    pub fn clear_min_graph_nodes(&mut self) {
        self.min_graph_nodes = 0;
    }

    // Param is passed by value, moved
    pub fn set_min_graph_nodes(&mut self, v: i32) {
        self.min_graph_nodes = v;
    }

    // bool experimental_disable_compressed_tensor_optimization = 26;


    pub fn get_experimental_disable_compressed_tensor_optimization(&self) -> bool {
        self.experimental_disable_compressed_tensor_optimization
    }
    pub fn clear_experimental_disable_compressed_tensor_optimization(&mut self) {
        self.experimental_disable_compressed_tensor_optimization = false;
    }

    // Param is passed by value, moved
    pub fn set_experimental_disable_compressed_tensor_optimization(&mut self, v: bool) {
        self.experimental_disable_compressed_tensor_optimization = v;
    }

    // .tensorflow.RewriterConfig.MemOptType memory_optimization = 4;


    pub fn get_memory_optimization(&self) -> RewriterConfig_MemOptType {
        self.memory_optimization
    }
    pub fn clear_memory_optimization(&mut self) {
        self.memory_optimization = RewriterConfig_MemOptType::DEFAULT_MEM_OPT;
    }

    // Param is passed by value, moved
    pub fn set_memory_optimization(&mut self, v: RewriterConfig_MemOptType) {
        self.memory_optimization = v;
    }

    // string memory_optimizer_target_node_name_scope = 6;


    pub fn get_memory_optimizer_target_node_name_scope(&self) -> &str {
        &self.memory_optimizer_target_node_name_scope
    }
    pub fn clear_memory_optimizer_target_node_name_scope(&mut self) {
        self.memory_optimizer_target_node_name_scope.clear();
    }

    // Param is passed by value, moved
    pub fn set_memory_optimizer_target_node_name_scope(&mut self, v: ::std::string::String) {
        self.memory_optimizer_target_node_name_scope = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_memory_optimizer_target_node_name_scope(&mut self) -> &mut ::std::string::String {
        &mut self.memory_optimizer_target_node_name_scope
    }

    // Take field
    pub fn take_memory_optimizer_target_node_name_scope(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.memory_optimizer_target_node_name_scope, ::std::string::String::new())
    }

    // int64 meta_optimizer_timeout_ms = 20;


    pub fn get_meta_optimizer_timeout_ms(&self) -> i64 {
        self.meta_optimizer_timeout_ms
    }
    pub fn clear_meta_optimizer_timeout_ms(&mut self) {
        self.meta_optimizer_timeout_ms = 0;
    }

    // Param is passed by value, moved
    pub fn set_meta_optimizer_timeout_ms(&mut self, v: i64) {
        self.meta_optimizer_timeout_ms = v;
    }

    // .tensorflow.AutoParallelOptions auto_parallel = 5;


    pub fn get_auto_parallel(&self) -> &AutoParallelOptions {
        self.auto_parallel.as_ref().unwrap_or_else(|| <AutoParallelOptions as ::protobuf::Message>::default_instance())
    }
    pub fn clear_auto_parallel(&mut self) {
        self.auto_parallel.clear();
    }

    pub fn has_auto_parallel(&self) -> bool {
        self.auto_parallel.is_some()
    }

    // Param is passed by value, moved
    pub fn set_auto_parallel(&mut self, v: AutoParallelOptions) {
        self.auto_parallel = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_auto_parallel(&mut self) -> &mut AutoParallelOptions {
        if self.auto_parallel.is_none() {
            self.auto_parallel.set_default();
        }
        self.auto_parallel.as_mut().unwrap()
    }

    // Take field
    pub fn take_auto_parallel(&mut self) -> AutoParallelOptions {
        self.auto_parallel.take().unwrap_or_else(|| AutoParallelOptions::new())
    }

    // bool fail_on_optimizer_errors = 21;


    pub fn get_fail_on_optimizer_errors(&self) -> bool {
        self.fail_on_optimizer_errors
    }
    pub fn clear_fail_on_optimizer_errors(&mut self) {
        self.fail_on_optimizer_errors = false;
    }

    // Param is passed by value, moved
    pub fn set_fail_on_optimizer_errors(&mut self, v: bool) {
        self.fail_on_optimizer_errors = v;
    }

    // .tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;


    pub fn get_scoped_allocator_opts(&self) -> &ScopedAllocatorOptions {
        self.scoped_allocator_opts.as_ref().unwrap_or_else(|| <ScopedAllocatorOptions as ::protobuf::Message>::default_instance())
    }
    pub fn clear_scoped_allocator_opts(&mut self) {
        self.scoped_allocator_opts.clear();
    }

    pub fn has_scoped_allocator_opts(&self) -> bool {
        self.scoped_allocator_opts.is_some()
    }

    // Param is passed by value, moved
    pub fn set_scoped_allocator_opts(&mut self, v: ScopedAllocatorOptions) {
        self.scoped_allocator_opts = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_scoped_allocator_opts(&mut self) -> &mut ScopedAllocatorOptions {
        if self.scoped_allocator_opts.is_none() {
            self.scoped_allocator_opts.set_default();
        }
        self.scoped_allocator_opts.as_mut().unwrap()
    }

    // Take field
    pub fn take_scoped_allocator_opts(&mut self) -> ScopedAllocatorOptions {
        self.scoped_allocator_opts.take().unwrap_or_else(|| ScopedAllocatorOptions::new())
    }

    // repeated string optimizers = 100;


    pub fn get_optimizers(&self) -> &[::std::string::String] {
        &self.optimizers
    }
    pub fn clear_optimizers(&mut self) {
        self.optimizers.clear();
    }

    // Param is passed by value, moved
    pub fn set_optimizers(&mut self, v: ::protobuf::RepeatedField<::std::string::String>) {
        self.optimizers = v;
    }

    // Mutable pointer to the field.
    pub fn mut_optimizers(&mut self) -> &mut ::protobuf::RepeatedField<::std::string::String> {
        &mut self.optimizers
    }

    // Take field
    pub fn take_optimizers(&mut self) -> ::protobuf::RepeatedField<::std::string::String> {
        ::std::mem::replace(&mut self.optimizers, ::protobuf::RepeatedField::new())
    }

    // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;


    pub fn get_custom_optimizers(&self) -> &[RewriterConfig_CustomGraphOptimizer] {
        &self.custom_optimizers
    }
    pub fn clear_custom_optimizers(&mut self) {
        self.custom_optimizers.clear();
    }

    // Param is passed by value, moved
    pub fn set_custom_optimizers(&mut self, v: ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer>) {
        self.custom_optimizers = v;
    }

    // Mutable pointer to the field.
    pub fn mut_custom_optimizers(&mut self) -> &mut ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer> {
        &mut self.custom_optimizers
    }

    // Take field
    pub fn take_custom_optimizers(&mut self) -> ::protobuf::RepeatedField<RewriterConfig_CustomGraphOptimizer> {
        ::std::mem::replace(&mut self.custom_optimizers, ::protobuf::RepeatedField::new())
    }

    // .tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;


    pub fn get_inter_optimizer_verifier_config(&self) -> &super::verifier_config::VerifierConfig {
        self.inter_optimizer_verifier_config.as_ref().unwrap_or_else(|| <super::verifier_config::VerifierConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_inter_optimizer_verifier_config(&mut self) {
        self.inter_optimizer_verifier_config.clear();
    }

    pub fn has_inter_optimizer_verifier_config(&self) -> bool {
        self.inter_optimizer_verifier_config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_inter_optimizer_verifier_config(&mut self, v: super::verifier_config::VerifierConfig) {
        self.inter_optimizer_verifier_config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_inter_optimizer_verifier_config(&mut self) -> &mut super::verifier_config::VerifierConfig {
        if self.inter_optimizer_verifier_config.is_none() {
            self.inter_optimizer_verifier_config.set_default();
        }
        self.inter_optimizer_verifier_config.as_mut().unwrap()
    }

    // Take field
    pub fn take_inter_optimizer_verifier_config(&mut self) -> super::verifier_config::VerifierConfig {
        self.inter_optimizer_verifier_config.take().unwrap_or_else(|| super::verifier_config::VerifierConfig::new())
    }

    // .tensorflow.VerifierConfig post_optimization_verifier_config = 301;


    pub fn get_post_optimization_verifier_config(&self) -> &super::verifier_config::VerifierConfig {
        self.post_optimization_verifier_config.as_ref().unwrap_or_else(|| <super::verifier_config::VerifierConfig as ::protobuf::Message>::default_instance())
    }
    pub fn clear_post_optimization_verifier_config(&mut self) {
        self.post_optimization_verifier_config.clear();
    }

    pub fn has_post_optimization_verifier_config(&self) -> bool {
        self.post_optimization_verifier_config.is_some()
    }

    // Param is passed by value, moved
    pub fn set_post_optimization_verifier_config(&mut self, v: super::verifier_config::VerifierConfig) {
        self.post_optimization_verifier_config = ::protobuf::SingularPtrField::some(v);
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_post_optimization_verifier_config(&mut self) -> &mut super::verifier_config::VerifierConfig {
        if self.post_optimization_verifier_config.is_none() {
            self.post_optimization_verifier_config.set_default();
        }
        self.post_optimization_verifier_config.as_mut().unwrap()
    }

    // Take field
    pub fn take_post_optimization_verifier_config(&mut self) -> super::verifier_config::VerifierConfig {
        self.post_optimization_verifier_config.take().unwrap_or_else(|| super::verifier_config::VerifierConfig::new())
    }
}

impl ::protobuf::Message for RewriterConfig {
    fn is_initialized(&self) -> bool {
        for v in &self.auto_parallel {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.scoped_allocator_opts {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.custom_optimizers {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.inter_optimizer_verifier_config {
            if !v.is_initialized() {
                return false;
            }
        };
        for v in &self.post_optimization_verifier_config {
            if !v.is_initialized() {
                return false;
            }
        };
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                50 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.cpu_layout_conversion, 50, &mut self.unknown_fields)?
                },
                1 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.layout_optimizer, 1, &mut self.unknown_fields)?
                },
                3 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.constant_folding, 3, &mut self.unknown_fields)?
                },
                13 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.shape_optimization, 13, &mut self.unknown_fields)?
                },
                14 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.remapping, 14, &mut self.unknown_fields)?
                },
                24 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.common_subgraph_elimination, 24, &mut self.unknown_fields)?
                },
                7 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.arithmetic_optimization, 7, &mut self.unknown_fields)?
                },
                8 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.dependency_optimization, 8, &mut self.unknown_fields)?
                },
                9 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.loop_optimization, 9, &mut self.unknown_fields)?
                },
                10 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.function_optimization, 10, &mut self.unknown_fields)?
                },
                11 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.debug_stripper, 11, &mut self.unknown_fields)?
                },
                2 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.disable_model_pruning = tmp;
                },
                15 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.scoped_allocator_optimization, 15, &mut self.unknown_fields)?
                },
                18 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.pin_to_host_optimization, 18, &mut self.unknown_fields)?
                },
                22 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.implementation_selector, 22, &mut self.unknown_fields)?
                },
                23 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.auto_mixed_precision, 23, &mut self.unknown_fields)?
                },
                25 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.auto_mixed_precision_mkl, 25, &mut self.unknown_fields)?
                },
                19 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.disable_meta_optimizer = tmp;
                },
                12 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.meta_optimizer_iterations, 12, &mut self.unknown_fields)?
                },
                17 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int32()?;
                    self.min_graph_nodes = tmp;
                },
                26 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.experimental_disable_compressed_tensor_optimization = tmp;
                },
                4 => {
                    ::protobuf::rt::read_proto3_enum_with_unknown_fields_into(wire_type, is, &mut self.memory_optimization, 4, &mut self.unknown_fields)?
                },
                6 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.memory_optimizer_target_node_name_scope)?;
                },
                20 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_int64()?;
                    self.meta_optimizer_timeout_ms = tmp;
                },
                5 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.auto_parallel)?;
                },
                21 => {
                    if wire_type != ::protobuf::wire_format::WireTypeVarint {
                        return ::std::result::Result::Err(::protobuf::rt::unexpected_wire_type(wire_type));
                    }
                    let tmp = is.read_bool()?;
                    self.fail_on_optimizer_errors = tmp;
                },
                16 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.scoped_allocator_opts)?;
                },
                100 => {
                    ::protobuf::rt::read_repeated_string_into(wire_type, is, &mut self.optimizers)?;
                },
                200 => {
                    ::protobuf::rt::read_repeated_message_into(wire_type, is, &mut self.custom_optimizers)?;
                },
                300 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.inter_optimizer_verifier_config)?;
                },
                301 => {
                    ::protobuf::rt::read_singular_message_into(wire_type, is, &mut self.post_optimization_verifier_config)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if self.cpu_layout_conversion != RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU {
            my_size += ::protobuf::rt::enum_size(50, self.cpu_layout_conversion);
        }
        if self.layout_optimizer != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(1, self.layout_optimizer);
        }
        if self.constant_folding != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(3, self.constant_folding);
        }
        if self.shape_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(13, self.shape_optimization);
        }
        if self.remapping != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(14, self.remapping);
        }
        if self.common_subgraph_elimination != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(24, self.common_subgraph_elimination);
        }
        if self.arithmetic_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(7, self.arithmetic_optimization);
        }
        if self.dependency_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(8, self.dependency_optimization);
        }
        if self.loop_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(9, self.loop_optimization);
        }
        if self.function_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(10, self.function_optimization);
        }
        if self.debug_stripper != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(11, self.debug_stripper);
        }
        if self.disable_model_pruning != false {
            my_size += 2;
        }
        if self.scoped_allocator_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(15, self.scoped_allocator_optimization);
        }
        if self.pin_to_host_optimization != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(18, self.pin_to_host_optimization);
        }
        if self.implementation_selector != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(22, self.implementation_selector);
        }
        if self.auto_mixed_precision != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(23, self.auto_mixed_precision);
        }
        if self.auto_mixed_precision_mkl != RewriterConfig_Toggle::DEFAULT {
            my_size += ::protobuf::rt::enum_size(25, self.auto_mixed_precision_mkl);
        }
        if self.disable_meta_optimizer != false {
            my_size += 3;
        }
        if self.meta_optimizer_iterations != RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS {
            my_size += ::protobuf::rt::enum_size(12, self.meta_optimizer_iterations);
        }
        if self.min_graph_nodes != 0 {
            my_size += ::protobuf::rt::value_size(17, self.min_graph_nodes, ::protobuf::wire_format::WireTypeVarint);
        }
        if self.experimental_disable_compressed_tensor_optimization != false {
            my_size += 3;
        }
        if self.memory_optimization != RewriterConfig_MemOptType::DEFAULT_MEM_OPT {
            my_size += ::protobuf::rt::enum_size(4, self.memory_optimization);
        }
        if !self.memory_optimizer_target_node_name_scope.is_empty() {
            my_size += ::protobuf::rt::string_size(6, &self.memory_optimizer_target_node_name_scope);
        }
        if self.meta_optimizer_timeout_ms != 0 {
            my_size += ::protobuf::rt::value_size(20, self.meta_optimizer_timeout_ms, ::protobuf::wire_format::WireTypeVarint);
        }
        if let Some(ref v) = self.auto_parallel.as_ref() {
            let len = v.compute_size();
            my_size += 1 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if self.fail_on_optimizer_errors != false {
            my_size += 3;
        }
        if let Some(ref v) = self.scoped_allocator_opts.as_ref() {
            let len = v.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        for value in &self.optimizers {
            my_size += ::protobuf::rt::string_size(100, &value);
        };
        for value in &self.custom_optimizers {
            let len = value.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        };
        if let Some(ref v) = self.inter_optimizer_verifier_config.as_ref() {
            let len = v.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        if let Some(ref v) = self.post_optimization_verifier_config.as_ref() {
            let len = v.compute_size();
            my_size += 2 + ::protobuf::rt::compute_raw_varint32_size(len) + len;
        }
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if self.cpu_layout_conversion != RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU {
            os.write_enum(50, ::protobuf::ProtobufEnum::value(&self.cpu_layout_conversion))?;
        }
        if self.layout_optimizer != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(1, ::protobuf::ProtobufEnum::value(&self.layout_optimizer))?;
        }
        if self.constant_folding != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(3, ::protobuf::ProtobufEnum::value(&self.constant_folding))?;
        }
        if self.shape_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(13, ::protobuf::ProtobufEnum::value(&self.shape_optimization))?;
        }
        if self.remapping != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(14, ::protobuf::ProtobufEnum::value(&self.remapping))?;
        }
        if self.common_subgraph_elimination != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(24, ::protobuf::ProtobufEnum::value(&self.common_subgraph_elimination))?;
        }
        if self.arithmetic_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(7, ::protobuf::ProtobufEnum::value(&self.arithmetic_optimization))?;
        }
        if self.dependency_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(8, ::protobuf::ProtobufEnum::value(&self.dependency_optimization))?;
        }
        if self.loop_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(9, ::protobuf::ProtobufEnum::value(&self.loop_optimization))?;
        }
        if self.function_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(10, ::protobuf::ProtobufEnum::value(&self.function_optimization))?;
        }
        if self.debug_stripper != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(11, ::protobuf::ProtobufEnum::value(&self.debug_stripper))?;
        }
        if self.disable_model_pruning != false {
            os.write_bool(2, self.disable_model_pruning)?;
        }
        if self.scoped_allocator_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(15, ::protobuf::ProtobufEnum::value(&self.scoped_allocator_optimization))?;
        }
        if self.pin_to_host_optimization != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(18, ::protobuf::ProtobufEnum::value(&self.pin_to_host_optimization))?;
        }
        if self.implementation_selector != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(22, ::protobuf::ProtobufEnum::value(&self.implementation_selector))?;
        }
        if self.auto_mixed_precision != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(23, ::protobuf::ProtobufEnum::value(&self.auto_mixed_precision))?;
        }
        if self.auto_mixed_precision_mkl != RewriterConfig_Toggle::DEFAULT {
            os.write_enum(25, ::protobuf::ProtobufEnum::value(&self.auto_mixed_precision_mkl))?;
        }
        if self.disable_meta_optimizer != false {
            os.write_bool(19, self.disable_meta_optimizer)?;
        }
        if self.meta_optimizer_iterations != RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS {
            os.write_enum(12, ::protobuf::ProtobufEnum::value(&self.meta_optimizer_iterations))?;
        }
        if self.min_graph_nodes != 0 {
            os.write_int32(17, self.min_graph_nodes)?;
        }
        if self.experimental_disable_compressed_tensor_optimization != false {
            os.write_bool(26, self.experimental_disable_compressed_tensor_optimization)?;
        }
        if self.memory_optimization != RewriterConfig_MemOptType::DEFAULT_MEM_OPT {
            os.write_enum(4, ::protobuf::ProtobufEnum::value(&self.memory_optimization))?;
        }
        if !self.memory_optimizer_target_node_name_scope.is_empty() {
            os.write_string(6, &self.memory_optimizer_target_node_name_scope)?;
        }
        if self.meta_optimizer_timeout_ms != 0 {
            os.write_int64(20, self.meta_optimizer_timeout_ms)?;
        }
        if let Some(ref v) = self.auto_parallel.as_ref() {
            os.write_tag(5, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if self.fail_on_optimizer_errors != false {
            os.write_bool(21, self.fail_on_optimizer_errors)?;
        }
        if let Some(ref v) = self.scoped_allocator_opts.as_ref() {
            os.write_tag(16, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        for v in &self.optimizers {
            os.write_string(100, &v)?;
        };
        for v in &self.custom_optimizers {
            os.write_tag(200, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        };
        if let Some(ref v) = self.inter_optimizer_verifier_config.as_ref() {
            os.write_tag(300, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        if let Some(ref v) = self.post_optimization_verifier_config.as_ref() {
            os.write_tag(301, ::protobuf::wire_format::WireTypeLengthDelimited)?;
            os.write_raw_varint32(v.get_cached_size())?;
            v.write_to_with_cached_sizes(os)?;
        }
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RewriterConfig {
        RewriterConfig::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_CpuLayout>>(
                "cpu_layout_conversion",
                |m: &RewriterConfig| { &m.cpu_layout_conversion },
                |m: &mut RewriterConfig| { &mut m.cpu_layout_conversion },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "layout_optimizer",
                |m: &RewriterConfig| { &m.layout_optimizer },
                |m: &mut RewriterConfig| { &mut m.layout_optimizer },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "constant_folding",
                |m: &RewriterConfig| { &m.constant_folding },
                |m: &mut RewriterConfig| { &mut m.constant_folding },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "shape_optimization",
                |m: &RewriterConfig| { &m.shape_optimization },
                |m: &mut RewriterConfig| { &mut m.shape_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "remapping",
                |m: &RewriterConfig| { &m.remapping },
                |m: &mut RewriterConfig| { &mut m.remapping },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "common_subgraph_elimination",
                |m: &RewriterConfig| { &m.common_subgraph_elimination },
                |m: &mut RewriterConfig| { &mut m.common_subgraph_elimination },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "arithmetic_optimization",
                |m: &RewriterConfig| { &m.arithmetic_optimization },
                |m: &mut RewriterConfig| { &mut m.arithmetic_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "dependency_optimization",
                |m: &RewriterConfig| { &m.dependency_optimization },
                |m: &mut RewriterConfig| { &mut m.dependency_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "loop_optimization",
                |m: &RewriterConfig| { &m.loop_optimization },
                |m: &mut RewriterConfig| { &mut m.loop_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "function_optimization",
                |m: &RewriterConfig| { &m.function_optimization },
                |m: &mut RewriterConfig| { &mut m.function_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "debug_stripper",
                |m: &RewriterConfig| { &m.debug_stripper },
                |m: &mut RewriterConfig| { &mut m.debug_stripper },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "disable_model_pruning",
                |m: &RewriterConfig| { &m.disable_model_pruning },
                |m: &mut RewriterConfig| { &mut m.disable_model_pruning },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "scoped_allocator_optimization",
                |m: &RewriterConfig| { &m.scoped_allocator_optimization },
                |m: &mut RewriterConfig| { &mut m.scoped_allocator_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "pin_to_host_optimization",
                |m: &RewriterConfig| { &m.pin_to_host_optimization },
                |m: &mut RewriterConfig| { &mut m.pin_to_host_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "implementation_selector",
                |m: &RewriterConfig| { &m.implementation_selector },
                |m: &mut RewriterConfig| { &mut m.implementation_selector },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "auto_mixed_precision",
                |m: &RewriterConfig| { &m.auto_mixed_precision },
                |m: &mut RewriterConfig| { &mut m.auto_mixed_precision },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_Toggle>>(
                "auto_mixed_precision_mkl",
                |m: &RewriterConfig| { &m.auto_mixed_precision_mkl },
                |m: &mut RewriterConfig| { &mut m.auto_mixed_precision_mkl },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "disable_meta_optimizer",
                |m: &RewriterConfig| { &m.disable_meta_optimizer },
                |m: &mut RewriterConfig| { &mut m.disable_meta_optimizer },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_NumIterationsType>>(
                "meta_optimizer_iterations",
                |m: &RewriterConfig| { &m.meta_optimizer_iterations },
                |m: &mut RewriterConfig| { &mut m.meta_optimizer_iterations },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt32>(
                "min_graph_nodes",
                |m: &RewriterConfig| { &m.min_graph_nodes },
                |m: &mut RewriterConfig| { &mut m.min_graph_nodes },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "experimental_disable_compressed_tensor_optimization",
                |m: &RewriterConfig| { &m.experimental_disable_compressed_tensor_optimization },
                |m: &mut RewriterConfig| { &mut m.experimental_disable_compressed_tensor_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeEnum<RewriterConfig_MemOptType>>(
                "memory_optimization",
                |m: &RewriterConfig| { &m.memory_optimization },
                |m: &mut RewriterConfig| { &mut m.memory_optimization },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "memory_optimizer_target_node_name_scope",
                |m: &RewriterConfig| { &m.memory_optimizer_target_node_name_scope },
                |m: &mut RewriterConfig| { &mut m.memory_optimizer_target_node_name_scope },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeInt64>(
                "meta_optimizer_timeout_ms",
                |m: &RewriterConfig| { &m.meta_optimizer_timeout_ms },
                |m: &mut RewriterConfig| { &mut m.meta_optimizer_timeout_ms },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<AutoParallelOptions>>(
                "auto_parallel",
                |m: &RewriterConfig| { &m.auto_parallel },
                |m: &mut RewriterConfig| { &mut m.auto_parallel },
            ));
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeBool>(
                "fail_on_optimizer_errors",
                |m: &RewriterConfig| { &m.fail_on_optimizer_errors },
                |m: &mut RewriterConfig| { &mut m.fail_on_optimizer_errors },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<ScopedAllocatorOptions>>(
                "scoped_allocator_opts",
                |m: &RewriterConfig| { &m.scoped_allocator_opts },
                |m: &mut RewriterConfig| { &mut m.scoped_allocator_opts },
            ));
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "optimizers",
                |m: &RewriterConfig| { &m.optimizers },
                |m: &mut RewriterConfig| { &mut m.optimizers },
            ));
            fields.push(::protobuf::reflect::accessor::make_repeated_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<RewriterConfig_CustomGraphOptimizer>>(
                "custom_optimizers",
                |m: &RewriterConfig| { &m.custom_optimizers },
                |m: &mut RewriterConfig| { &mut m.custom_optimizers },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<super::verifier_config::VerifierConfig>>(
                "inter_optimizer_verifier_config",
                |m: &RewriterConfig| { &m.inter_optimizer_verifier_config },
                |m: &mut RewriterConfig| { &mut m.inter_optimizer_verifier_config },
            ));
            fields.push(::protobuf::reflect::accessor::make_singular_ptr_field_accessor::<_, ::protobuf::types::ProtobufTypeMessage<super::verifier_config::VerifierConfig>>(
                "post_optimization_verifier_config",
                |m: &RewriterConfig| { &m.post_optimization_verifier_config },
                |m: &mut RewriterConfig| { &mut m.post_optimization_verifier_config },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RewriterConfig>(
                "RewriterConfig",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RewriterConfig {
        static instance: ::protobuf::rt::LazyV2<RewriterConfig> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RewriterConfig::new)
    }
}

impl ::protobuf::Clear for RewriterConfig {
    fn clear(&mut self) {
        self.cpu_layout_conversion = RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU;
        self.layout_optimizer = RewriterConfig_Toggle::DEFAULT;
        self.constant_folding = RewriterConfig_Toggle::DEFAULT;
        self.shape_optimization = RewriterConfig_Toggle::DEFAULT;
        self.remapping = RewriterConfig_Toggle::DEFAULT;
        self.common_subgraph_elimination = RewriterConfig_Toggle::DEFAULT;
        self.arithmetic_optimization = RewriterConfig_Toggle::DEFAULT;
        self.dependency_optimization = RewriterConfig_Toggle::DEFAULT;
        self.loop_optimization = RewriterConfig_Toggle::DEFAULT;
        self.function_optimization = RewriterConfig_Toggle::DEFAULT;
        self.debug_stripper = RewriterConfig_Toggle::DEFAULT;
        self.disable_model_pruning = false;
        self.scoped_allocator_optimization = RewriterConfig_Toggle::DEFAULT;
        self.pin_to_host_optimization = RewriterConfig_Toggle::DEFAULT;
        self.implementation_selector = RewriterConfig_Toggle::DEFAULT;
        self.auto_mixed_precision = RewriterConfig_Toggle::DEFAULT;
        self.auto_mixed_precision_mkl = RewriterConfig_Toggle::DEFAULT;
        self.disable_meta_optimizer = false;
        self.meta_optimizer_iterations = RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS;
        self.min_graph_nodes = 0;
        self.experimental_disable_compressed_tensor_optimization = false;
        self.memory_optimization = RewriterConfig_MemOptType::DEFAULT_MEM_OPT;
        self.memory_optimizer_target_node_name_scope.clear();
        self.meta_optimizer_timeout_ms = 0;
        self.auto_parallel.clear();
        self.fail_on_optimizer_errors = false;
        self.scoped_allocator_opts.clear();
        self.optimizers.clear();
        self.custom_optimizers.clear();
        self.inter_optimizer_verifier_config.clear();
        self.post_optimization_verifier_config.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RewriterConfig {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(PartialEq,Clone,Default)]
pub struct RewriterConfig_CustomGraphOptimizer {
    // message fields
    pub name: ::std::string::String,
    pub parameter_map: ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue>,
    // special fields
    pub unknown_fields: ::protobuf::UnknownFields,
    pub cached_size: ::protobuf::CachedSize,
}

impl<'a> ::std::default::Default for &'a RewriterConfig_CustomGraphOptimizer {
    fn default() -> &'a RewriterConfig_CustomGraphOptimizer {
        <RewriterConfig_CustomGraphOptimizer as ::protobuf::Message>::default_instance()
    }
}

impl RewriterConfig_CustomGraphOptimizer {
    pub fn new() -> RewriterConfig_CustomGraphOptimizer {
        ::std::default::Default::default()
    }

    // string name = 1;


    pub fn get_name(&self) -> &str {
        &self.name
    }
    pub fn clear_name(&mut self) {
        self.name.clear();
    }

    // Param is passed by value, moved
    pub fn set_name(&mut self, v: ::std::string::String) {
        self.name = v;
    }

    // Mutable pointer to the field.
    // If field is not initialized, it is initialized with default value first.
    pub fn mut_name(&mut self) -> &mut ::std::string::String {
        &mut self.name
    }

    // Take field
    pub fn take_name(&mut self) -> ::std::string::String {
        ::std::mem::replace(&mut self.name, ::std::string::String::new())
    }

    // repeated .tensorflow.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry parameter_map = 2;


    pub fn get_parameter_map(&self) -> &::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        &self.parameter_map
    }
    pub fn clear_parameter_map(&mut self) {
        self.parameter_map.clear();
    }

    // Param is passed by value, moved
    pub fn set_parameter_map(&mut self, v: ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue>) {
        self.parameter_map = v;
    }

    // Mutable pointer to the field.
    pub fn mut_parameter_map(&mut self) -> &mut ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        &mut self.parameter_map
    }

    // Take field
    pub fn take_parameter_map(&mut self) -> ::std::collections::HashMap<::std::string::String, super::attr_value::AttrValue> {
        ::std::mem::replace(&mut self.parameter_map, ::std::collections::HashMap::new())
    }
}

impl ::protobuf::Message for RewriterConfig_CustomGraphOptimizer {
    fn is_initialized(&self) -> bool {
        true
    }

    fn merge_from(&mut self, is: &mut ::protobuf::CodedInputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        while !is.eof()? {
            let (field_number, wire_type) = is.read_tag_unpack()?;
            match field_number {
                1 => {
                    ::protobuf::rt::read_singular_proto3_string_into(wire_type, is, &mut self.name)?;
                },
                2 => {
                    ::protobuf::rt::read_map_into::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(wire_type, is, &mut self.parameter_map)?;
                },
                _ => {
                    ::protobuf::rt::read_unknown_or_skip_group(field_number, wire_type, is, self.mut_unknown_fields())?;
                },
            };
        }
        ::std::result::Result::Ok(())
    }

    // Compute sizes of nested messages
    #[allow(unused_variables)]
    fn compute_size(&self) -> u32 {
        let mut my_size = 0;
        if !self.name.is_empty() {
            my_size += ::protobuf::rt::string_size(1, &self.name);
        }
        my_size += ::protobuf::rt::compute_map_size::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(2, &self.parameter_map);
        my_size += ::protobuf::rt::unknown_fields_size(self.get_unknown_fields());
        self.cached_size.set(my_size);
        my_size
    }

    fn write_to_with_cached_sizes(&self, os: &mut ::protobuf::CodedOutputStream<'_>) -> ::protobuf::ProtobufResult<()> {
        if !self.name.is_empty() {
            os.write_string(1, &self.name)?;
        }
        ::protobuf::rt::write_map_with_cached_sizes::<::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(2, &self.parameter_map, os)?;
        os.write_unknown_fields(self.get_unknown_fields())?;
        ::std::result::Result::Ok(())
    }

    fn get_cached_size(&self) -> u32 {
        self.cached_size.get()
    }

    fn get_unknown_fields(&self) -> &::protobuf::UnknownFields {
        &self.unknown_fields
    }

    fn mut_unknown_fields(&mut self) -> &mut ::protobuf::UnknownFields {
        &mut self.unknown_fields
    }

    fn as_any(&self) -> &dyn (::std::any::Any) {
        self as &dyn (::std::any::Any)
    }
    fn as_any_mut(&mut self) -> &mut dyn (::std::any::Any) {
        self as &mut dyn (::std::any::Any)
    }
    fn into_any(self: ::std::boxed::Box<Self>) -> ::std::boxed::Box<dyn (::std::any::Any)> {
        self
    }

    fn descriptor(&self) -> &'static ::protobuf::reflect::MessageDescriptor {
        Self::descriptor_static()
    }

    fn new() -> RewriterConfig_CustomGraphOptimizer {
        RewriterConfig_CustomGraphOptimizer::new()
    }

    fn descriptor_static() -> &'static ::protobuf::reflect::MessageDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::MessageDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            let mut fields = ::std::vec::Vec::new();
            fields.push(::protobuf::reflect::accessor::make_simple_field_accessor::<_, ::protobuf::types::ProtobufTypeString>(
                "name",
                |m: &RewriterConfig_CustomGraphOptimizer| { &m.name },
                |m: &mut RewriterConfig_CustomGraphOptimizer| { &mut m.name },
            ));
            fields.push(::protobuf::reflect::accessor::make_map_accessor::<_, ::protobuf::types::ProtobufTypeString, ::protobuf::types::ProtobufTypeMessage<super::attr_value::AttrValue>>(
                "parameter_map",
                |m: &RewriterConfig_CustomGraphOptimizer| { &m.parameter_map },
                |m: &mut RewriterConfig_CustomGraphOptimizer| { &mut m.parameter_map },
            ));
            ::protobuf::reflect::MessageDescriptor::new_pb_name::<RewriterConfig_CustomGraphOptimizer>(
                "RewriterConfig.CustomGraphOptimizer",
                fields,
                file_descriptor_proto()
            )
        })
    }

    fn default_instance() -> &'static RewriterConfig_CustomGraphOptimizer {
        static instance: ::protobuf::rt::LazyV2<RewriterConfig_CustomGraphOptimizer> = ::protobuf::rt::LazyV2::INIT;
        instance.get(RewriterConfig_CustomGraphOptimizer::new)
    }
}

impl ::protobuf::Clear for RewriterConfig_CustomGraphOptimizer {
    fn clear(&mut self) {
        self.name.clear();
        self.parameter_map.clear();
        self.unknown_fields.clear();
    }
}

impl ::std::fmt::Debug for RewriterConfig_CustomGraphOptimizer {
    fn fmt(&self, f: &mut ::std::fmt::Formatter<'_>) -> ::std::fmt::Result {
        ::protobuf::text_format::fmt(self, f)
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_CustomGraphOptimizer {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Message(self)
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_Toggle {
    DEFAULT = 0,
    ON = 1,
    OFF = 2,
    AGGRESSIVE = 3,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_Toggle {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_Toggle> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_Toggle::DEFAULT),
            1 => ::std::option::Option::Some(RewriterConfig_Toggle::ON),
            2 => ::std::option::Option::Some(RewriterConfig_Toggle::OFF),
            3 => ::std::option::Option::Some(RewriterConfig_Toggle::AGGRESSIVE),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_Toggle] = &[
            RewriterConfig_Toggle::DEFAULT,
            RewriterConfig_Toggle::ON,
            RewriterConfig_Toggle::OFF,
            RewriterConfig_Toggle::AGGRESSIVE,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RewriterConfig_Toggle>("RewriterConfig.Toggle", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RewriterConfig_Toggle {
}

impl ::std::default::Default for RewriterConfig_Toggle {
    fn default() -> Self {
        RewriterConfig_Toggle::DEFAULT
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_Toggle {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_CpuLayout {
    NO_CONVERSION_ON_CPU = 0,
    NCHW_TO_NHWC = 1,
    NHWC_TO_NCHW = 2,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_CpuLayout {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_CpuLayout> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU),
            1 => ::std::option::Option::Some(RewriterConfig_CpuLayout::NCHW_TO_NHWC),
            2 => ::std::option::Option::Some(RewriterConfig_CpuLayout::NHWC_TO_NCHW),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_CpuLayout] = &[
            RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU,
            RewriterConfig_CpuLayout::NCHW_TO_NHWC,
            RewriterConfig_CpuLayout::NHWC_TO_NCHW,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RewriterConfig_CpuLayout>("RewriterConfig.CpuLayout", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RewriterConfig_CpuLayout {
}

impl ::std::default::Default for RewriterConfig_CpuLayout {
    fn default() -> Self {
        RewriterConfig_CpuLayout::NO_CONVERSION_ON_CPU
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_CpuLayout {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_NumIterationsType {
    DEFAULT_NUM_ITERS = 0,
    ONE = 1,
    TWO = 2,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_NumIterationsType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_NumIterationsType> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS),
            1 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::ONE),
            2 => ::std::option::Option::Some(RewriterConfig_NumIterationsType::TWO),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_NumIterationsType] = &[
            RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS,
            RewriterConfig_NumIterationsType::ONE,
            RewriterConfig_NumIterationsType::TWO,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RewriterConfig_NumIterationsType>("RewriterConfig.NumIterationsType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RewriterConfig_NumIterationsType {
}

impl ::std::default::Default for RewriterConfig_NumIterationsType {
    fn default() -> Self {
        RewriterConfig_NumIterationsType::DEFAULT_NUM_ITERS
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_NumIterationsType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

#[derive(Clone,PartialEq,Eq,Debug,Hash)]
pub enum RewriterConfig_MemOptType {
    DEFAULT_MEM_OPT = 0,
    NO_MEM_OPT = 1,
    MANUAL = 2,
    SWAPPING_HEURISTICS = 4,
    RECOMPUTATION_HEURISTICS = 5,
    SCHEDULING_HEURISTICS = 6,
    HEURISTICS = 3,
}

impl ::protobuf::ProtobufEnum for RewriterConfig_MemOptType {
    fn value(&self) -> i32 {
        *self as i32
    }

    fn from_i32(value: i32) -> ::std::option::Option<RewriterConfig_MemOptType> {
        match value {
            0 => ::std::option::Option::Some(RewriterConfig_MemOptType::DEFAULT_MEM_OPT),
            1 => ::std::option::Option::Some(RewriterConfig_MemOptType::NO_MEM_OPT),
            2 => ::std::option::Option::Some(RewriterConfig_MemOptType::MANUAL),
            4 => ::std::option::Option::Some(RewriterConfig_MemOptType::SWAPPING_HEURISTICS),
            5 => ::std::option::Option::Some(RewriterConfig_MemOptType::RECOMPUTATION_HEURISTICS),
            6 => ::std::option::Option::Some(RewriterConfig_MemOptType::SCHEDULING_HEURISTICS),
            3 => ::std::option::Option::Some(RewriterConfig_MemOptType::HEURISTICS),
            _ => ::std::option::Option::None
        }
    }

    fn values() -> &'static [Self] {
        static values: &'static [RewriterConfig_MemOptType] = &[
            RewriterConfig_MemOptType::DEFAULT_MEM_OPT,
            RewriterConfig_MemOptType::NO_MEM_OPT,
            RewriterConfig_MemOptType::MANUAL,
            RewriterConfig_MemOptType::SWAPPING_HEURISTICS,
            RewriterConfig_MemOptType::RECOMPUTATION_HEURISTICS,
            RewriterConfig_MemOptType::SCHEDULING_HEURISTICS,
            RewriterConfig_MemOptType::HEURISTICS,
        ];
        values
    }

    fn enum_descriptor_static() -> &'static ::protobuf::reflect::EnumDescriptor {
        static descriptor: ::protobuf::rt::LazyV2<::protobuf::reflect::EnumDescriptor> = ::protobuf::rt::LazyV2::INIT;
        descriptor.get(|| {
            ::protobuf::reflect::EnumDescriptor::new_pb_name::<RewriterConfig_MemOptType>("RewriterConfig.MemOptType", file_descriptor_proto())
        })
    }
}

impl ::std::marker::Copy for RewriterConfig_MemOptType {
}

impl ::std::default::Default for RewriterConfig_MemOptType {
    fn default() -> Self {
        RewriterConfig_MemOptType::DEFAULT_MEM_OPT
    }
}

impl ::protobuf::reflect::ProtobufValue for RewriterConfig_MemOptType {
    fn as_ref(&self) -> ::protobuf::reflect::ReflectValueRef {
        ::protobuf::reflect::ReflectValueRef::Enum(::protobuf::ProtobufEnum::descriptor(self))
    }
}

static file_descriptor_proto_data: &'static [u8] = b"\
    \n.tensorflow/core/protobuf/rewriter_config.proto\x12\ntensorflow\x1a*te\
    nsorflow/core/framework/attr_value.proto\x1a.tensorflow/core/protobuf/ve\
    rifier_config.proto\"P\n\x13AutoParallelOptions\x12\x16\n\x06enable\x18\
    \x01\x20\x01(\x08R\x06enable\x12!\n\x0cnum_replicas\x18\x02\x20\x01(\x05\
    R\x0bnumReplicas\"5\n\x16ScopedAllocatorOptions\x12\x1b\n\tenable_op\x18\
    \x01\x20\x03(\tR\x08enableOp\"\xba\x18\n\x0eRewriterConfig\x12X\n\x15cpu\
    _layout_conversion\x182\x20\x01(\x0e2$.tensorflow.RewriterConfig.CpuLayo\
    utR\x13cpuLayoutConversion\x12L\n\x10layout_optimizer\x18\x01\x20\x01(\
    \x0e2!.tensorflow.RewriterConfig.ToggleR\x0flayoutOptimizer\x12L\n\x10co\
    nstant_folding\x18\x03\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\
    \x0fconstantFolding\x12P\n\x12shape_optimization\x18\r\x20\x01(\x0e2!.te\
    nsorflow.RewriterConfig.ToggleR\x11shapeOptimization\x12?\n\tremapping\
    \x18\x0e\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\tremapping\x12\
    a\n\x1bcommon_subgraph_elimination\x18\x18\x20\x01(\x0e2!.tensorflow.Rew\
    riterConfig.ToggleR\x19commonSubgraphElimination\x12Z\n\x17arithmetic_op\
    timization\x18\x07\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x16a\
    rithmeticOptimization\x12Z\n\x17dependency_optimization\x18\x08\x20\x01(\
    \x0e2!.tensorflow.RewriterConfig.ToggleR\x16dependencyOptimization\x12N\
    \n\x11loop_optimization\x18\t\x20\x01(\x0e2!.tensorflow.RewriterConfig.T\
    oggleR\x10loopOptimization\x12V\n\x15function_optimization\x18\n\x20\x01\
    (\x0e2!.tensorflow.RewriterConfig.ToggleR\x14functionOptimization\x12H\n\
    \x0edebug_stripper\x18\x0b\x20\x01(\x0e2!.tensorflow.RewriterConfig.Togg\
    leR\rdebugStripper\x122\n\x15disable_model_pruning\x18\x02\x20\x01(\x08R\
    \x13disableModelPruning\x12e\n\x1dscoped_allocator_optimization\x18\x0f\
    \x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x1bscopedAllocatorOpti\
    mization\x12Z\n\x18pin_to_host_optimization\x18\x12\x20\x01(\x0e2!.tenso\
    rflow.RewriterConfig.ToggleR\x15pinToHostOptimization\x12Z\n\x17implemen\
    tation_selector\x18\x16\x20\x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\
    \x16implementationSelector\x12S\n\x14auto_mixed_precision\x18\x17\x20\
    \x01(\x0e2!.tensorflow.RewriterConfig.ToggleR\x12autoMixedPrecision\x12Z\
    \n\x18auto_mixed_precision_mkl\x18\x19\x20\x01(\x0e2!.tensorflow.Rewrite\
    rConfig.ToggleR\x15autoMixedPrecisionMkl\x124\n\x16disable_meta_optimize\
    r\x18\x13\x20\x01(\x08R\x14disableMetaOptimizer\x12h\n\x19meta_optimizer\
    _iterations\x18\x0c\x20\x01(\x0e2,.tensorflow.RewriterConfig.NumIteratio\
    nsTypeR\x17metaOptimizerIterations\x12&\n\x0fmin_graph_nodes\x18\x11\x20\
    \x01(\x05R\rminGraphNodes\x12l\n3experimental_disable_compressed_tensor_\
    optimization\x18\x1a\x20\x01(\x08R/experimentalDisableCompressedTensorOp\
    timization\x12V\n\x13memory_optimization\x18\x04\x20\x01(\x0e2%.tensorfl\
    ow.RewriterConfig.MemOptTypeR\x12memoryOptimization\x12S\n'memory_optimi\
    zer_target_node_name_scope\x18\x06\x20\x01(\tR\"memoryOptimizerTargetNod\
    eNameScope\x129\n\x19meta_optimizer_timeout_ms\x18\x14\x20\x01(\x03R\x16\
    metaOptimizerTimeoutMs\x12D\n\rauto_parallel\x18\x05\x20\x01(\x0b2\x1f.t\
    ensorflow.AutoParallelOptionsR\x0cautoParallel\x127\n\x18fail_on_optimiz\
    er_errors\x18\x15\x20\x01(\x08R\x15failOnOptimizerErrors\x12V\n\x15scope\
    d_allocator_opts\x18\x10\x20\x01(\x0b2\".tensorflow.ScopedAllocatorOptio\
    nsR\x13scopedAllocatorOpts\x12\x1e\n\noptimizers\x18d\x20\x03(\tR\noptim\
    izers\x12]\n\x11custom_optimizers\x18\xc8\x01\x20\x03(\x0b2/.tensorflow.\
    RewriterConfig.CustomGraphOptimizerR\x10customOptimizers\x12b\n\x1finter\
    _optimizer_verifier_config\x18\xac\x02\x20\x01(\x0b2\x1a.tensorflow.Veri\
    fierConfigR\x1cinterOptimizerVerifierConfig\x12f\n!post_optimization_ver\
    ifier_config\x18\xad\x02\x20\x01(\x0b2\x1a.tensorflow.VerifierConfigR\
    \x1epostOptimizationVerifierConfig\x1a\xea\x01\n\x14CustomGraphOptimizer\
    \x12\x12\n\x04name\x18\x01\x20\x01(\tR\x04name\x12f\n\rparameter_map\x18\
    \x02\x20\x03(\x0b2A.tensorflow.RewriterConfig.CustomGraphOptimizer.Param\
    eterMapEntryR\x0cparameterMap\x1aV\n\x11ParameterMapEntry\x12\x10\n\x03k\
    ey\x18\x01\x20\x01(\tR\x03key\x12+\n\x05value\x18\x02\x20\x01(\x0b2\x15.\
    tensorflow.AttrValueR\x05value:\x028\x01\"6\n\x06Toggle\x12\x0b\n\x07DEF\
    AULT\x10\0\x12\x06\n\x02ON\x10\x01\x12\x07\n\x03OFF\x10\x02\x12\x0e\n\nA\
    GGRESSIVE\x10\x03\"I\n\tCpuLayout\x12\x18\n\x14NO_CONVERSION_ON_CPU\x10\
    \0\x12\x10\n\x0cNCHW_TO_NHWC\x10\x01\x12\x10\n\x0cNHWC_TO_NCHW\x10\x02\"\
    <\n\x11NumIterationsType\x12\x15\n\x11DEFAULT_NUM_ITERS\x10\0\x12\x07\n\
    \x03ONE\x10\x01\x12\x07\n\x03TWO\x10\x02\"\x9f\x01\n\nMemOptType\x12\x13\
    \n\x0fDEFAULT_MEM_OPT\x10\0\x12\x0e\n\nNO_MEM_OPT\x10\x01\x12\n\n\x06MAN\
    UAL\x10\x02\x12\x17\n\x13SWAPPING_HEURISTICS\x10\x04\x12\x1c\n\x18RECOMP\
    UTATION_HEURISTICS\x10\x05\x12\x19\n\x15SCHEDULING_HEURISTICS\x10\x06\
    \x12\x0e\n\nHEURISTICS\x10\x03Bs\n\x18org.tensorflow.frameworkB\x14Rewri\
    terConfigProtosP\x01Z<github.com/tensorflow/tensorflow/tensorflow/go/cor\
    e/protobuf\xf8\x01\x01J\xd3G\n\x07\x12\x05\0\0\xce\x01\x01\n\x08\n\x01\
    \x0c\x12\x03\0\0\x12\n\x08\n\x01\x02\x12\x03\x02\0\x13\n\t\n\x02\x03\0\
    \x12\x03\x04\04\n\t\n\x02\x03\x01\x12\x03\x05\08\n\x08\n\x01\x08\x12\x03\
    \x07\0\x1f\n\t\n\x02\x08\x1f\x12\x03\x07\0\x1f\n\x08\n\x01\x08\x12\x03\
    \x08\05\n\t\n\x02\x08\x08\x12\x03\x08\05\n\x08\n\x01\x08\x12\x03\t\0\"\n\
    \t\n\x02\x08\n\x12\x03\t\0\"\n\x08\n\x01\x08\x12\x03\n\01\n\t\n\x02\x08\
    \x01\x12\x03\n\01\n\x08\n\x01\x08\x12\x03\x0b\0S\n\t\n\x02\x08\x0b\x12\
    \x03\x0b\0S\n\n\n\x02\x04\0\x12\x04\r\0\x10\x01\n\n\n\x03\x04\0\x01\x12\
    \x03\r\x08\x1b\n\x0b\n\x04\x04\0\x02\0\x12\x03\x0e\x02\x12\n\x0c\n\x05\
    \x04\0\x02\0\x05\x12\x03\x0e\x02\x06\n\x0c\n\x05\x04\0\x02\0\x01\x12\x03\
    \x0e\x07\r\n\x0c\n\x05\x04\0\x02\0\x03\x12\x03\x0e\x10\x11\n\x0b\n\x04\
    \x04\0\x02\x01\x12\x03\x0f\x02\x19\n\x0c\n\x05\x04\0\x02\x01\x05\x12\x03\
    \x0f\x02\x07\n\x0c\n\x05\x04\0\x02\x01\x01\x12\x03\x0f\x08\x14\n\x0c\n\
    \x05\x04\0\x02\x01\x03\x12\x03\x0f\x17\x18\n\n\n\x02\x04\x01\x12\x04\x12\
    \0\x15\x01\n\n\n\x03\x04\x01\x01\x12\x03\x12\x08\x1e\nC\n\x04\x04\x01\
    \x02\0\x12\x03\x14\x02\x20\x1a6\x20If\x20present,\x20only\x20perform\x20\
    optimization\x20for\x20these\x20ops.\n\n\x0c\n\x05\x04\x01\x02\0\x04\x12\
    \x03\x14\x02\n\n\x0c\n\x05\x04\x01\x02\0\x05\x12\x03\x14\x0b\x11\n\x0c\n\
    \x05\x04\x01\x02\0\x01\x12\x03\x14\x12\x1b\n\x0c\n\x05\x04\x01\x02\0\x03\
    \x12\x03\x14\x1e\x1f\ns\n\x02\x04\x02\x12\x05\x17\0\xce\x01\x01\"f\x20Gr\
    aph\x20rewriting\x20is\x20experimental\x20and\x20subject\x20to\x20change\
    ,\x20not\x20covered\x20by\x20any\n\x20API\x20stability\x20guarantees.\n\
    \n\n\n\x03\x04\x02\x01\x12\x03\x17\x08\x16\n\xc6\x01\n\x04\x04\x02\x04\0\
    \x12\x04\x1f\x02'\x032\xb7\x01\x20Configuration\x20options\x20for\x20the\
    \x20meta-optimizer.\x20Unless\x20otherwise\x20noted,\x20these\n\x20confi\
    guration\x20options\x20do\x20not\x20apply\x20to\x20explicitly\x20trigger\
    ed\x20optimization\n\x20passes\x20in\x20the\x20optimizers\x20field.\n\n\
    \x0c\n\x05\x04\x02\x04\0\x01\x12\x03\x1f\x07\r\n\r\n\x06\x04\x02\x04\0\
    \x02\0\x12\x03\x20\x04\x10\n\x0e\n\x07\x04\x02\x04\0\x02\0\x01\x12\x03\
    \x20\x04\x0b\n\x0e\n\x07\x04\x02\x04\0\x02\0\x02\x12\x03\x20\x0e\x0f\n\r\
    \n\x06\x04\x02\x04\0\x02\x01\x12\x03!\x04\x0b\n\x0e\n\x07\x04\x02\x04\0\
    \x02\x01\x01\x12\x03!\x04\x06\n\x0e\n\x07\x04\x02\x04\0\x02\x01\x02\x12\
    \x03!\t\n\n\r\n\x06\x04\x02\x04\0\x02\x02\x12\x03\"\x04\x0c\n\x0e\n\x07\
    \x04\x02\x04\0\x02\x02\x01\x12\x03\"\x04\x07\n\x0e\n\x07\x04\x02\x04\0\
    \x02\x02\x02\x12\x03\"\n\x0b\n\xaf\x01\n\x06\x04\x02\x04\0\x02\x03\x12\
    \x03&\x04\x13\x1a\x9f\x01\x20Enable\x20some\x20aggressive\x20optimizatio\
    ns\x20that\x20use\x20assumptions\x20that\x20TF\x20graphs\n\x20may\x20bre\
    ak.\x20For\x20example,\x20assume\x20the\x20shape\x20of\x20a\x20placehold\
    er\x20matches\x20its\n\x20actual\x20feed.\n\n\x0e\n\x07\x04\x02\x04\0\
    \x02\x03\x01\x12\x03&\x04\x0e\n\x0e\n\x07\x04\x02\x04\0\x02\x03\x02\x12\
    \x03&\x11\x12\nX\n\x04\x04\x02\x04\x01\x12\x04*\x02.\x03\x1aJ\x20Enum\
    \x20for\x20layout\x20conversion\x20between\x20NCHW\x20and\x20NHWC\x20on\
    \x20CPU.\x20Default\x20is\x20OFF.\n\n\x0c\n\x05\x04\x02\x04\x01\x01\x12\
    \x03*\x07\x10\n\r\n\x06\x04\x02\x04\x01\x02\0\x12\x03+\x04\x1d\n\x0e\n\
    \x07\x04\x02\x04\x01\x02\0\x01\x12\x03+\x04\x18\n\x0e\n\x07\x04\x02\x04\
    \x01\x02\0\x02\x12\x03+\x1b\x1c\n\r\n\x06\x04\x02\x04\x01\x02\x01\x12\
    \x03,\x04\x15\n\x0e\n\x07\x04\x02\x04\x01\x02\x01\x01\x12\x03,\x04\x10\n\
    \x0e\n\x07\x04\x02\x04\x01\x02\x01\x02\x12\x03,\x13\x14\n\r\n\x06\x04\
    \x02\x04\x01\x02\x02\x12\x03-\x04\x15\n\x0e\n\x07\x04\x02\x04\x01\x02\
    \x02\x01\x12\x03-\x04\x10\n\x0e\n\x07\x04\x02\x04\x01\x02\x02\x02\x12\
    \x03-\x13\x14\nj\n\x04\x04\x02\x04\x02\x12\x042\x026\x03\x1a\\\x20Enum\
    \x20controlling\x20the\x20number\x20of\x20times\x20to\x20run\x20optimize\
    rs.\x20The\x20default\x20is\x20to\n\x20run\x20them\x20twice.\n\n\x0c\n\
    \x05\x04\x02\x04\x02\x01\x12\x032\x07\x18\n\r\n\x06\x04\x02\x04\x02\x02\
    \0\x12\x033\x04\x1a\n\x0e\n\x07\x04\x02\x04\x02\x02\0\x01\x12\x033\x04\
    \x15\n\x0e\n\x07\x04\x02\x04\x02\x02\0\x02\x12\x033\x18\x19\n\r\n\x06\
    \x04\x02\x04\x02\x02\x01\x12\x034\x04\x0c\n\x0e\n\x07\x04\x02\x04\x02\
    \x02\x01\x01\x12\x034\x04\x07\n\x0e\n\x07\x04\x02\x04\x02\x02\x01\x02\
    \x12\x034\n\x0b\n\r\n\x06\x04\x02\x04\x02\x02\x02\x12\x035\x04\x0c\n\x0e\
    \n\x07\x04\x02\x04\x02\x02\x02\x01\x12\x035\x04\x07\n\x0e\n\x07\x04\x02\
    \x04\x02\x02\x02\x02\x12\x035\n\x0b\n=\n\x04\x04\x02\x02\0\x12\x039\x02'\
    \x1a0\x20CPU\x20Conversion\x20settings\x20between\x20NHCW\x20and\x20NCHW\
    .\n\n\x0c\n\x05\x04\x02\x02\0\x06\x12\x039\x02\x0b\n\x0c\n\x05\x04\x02\
    \x02\0\x01\x12\x039\x0c!\n\x0c\n\x05\x04\x02\x02\0\x03\x12\x039$&\nu\n\
    \x04\x04\x02\x02\x01\x12\x03=\x02\x1e\x1ah\x20Optimize\x20tensor\x20layo\
    uts\x20(default\x20is\x20ON)\n\x20e.g.\x20This\x20will\x20try\x20to\x20u\
    se\x20NCHW\x20layout\x20on\x20GPU\x20which\x20is\x20faster.\n\n\x0c\n\
    \x05\x04\x02\x02\x01\x06\x12\x03=\x02\x08\n\x0c\n\x05\x04\x02\x02\x01\
    \x01\x12\x03=\t\x19\n\x0c\n\x05\x04\x02\x02\x01\x03\x12\x03=\x1c\x1d\n\
    \x91\x01\n\x04\x04\x02\x02\x02\x12\x03A\x02\x1e\x1a\x83\x01\x20Fold\x20c\
    onstants\x20(default\x20is\x20ON)\n\x20Statically\x20infer\x20the\x20val\
    ue\x20of\x20tensors\x20when\x20possible,\x20and\x20materialize\x20the\n\
    \x20result\x20using\x20constants.\n\n\x0c\n\x05\x04\x02\x02\x02\x06\x12\
    \x03A\x02\x08\n\x0c\n\x05\x04\x02\x02\x02\x01\x12\x03A\t\x19\n\x0c\n\x05\
    \x04\x02\x02\x02\x03\x12\x03A\x1c\x1d\nY\n\x04\x04\x02\x02\x03\x12\x03D\
    \x02!\x1aL\x20Shape\x20optimizations\x20(default\x20is\x20ON)\n\x20Simpl\
    ify\x20computations\x20made\x20on\x20shapes.\n\n\x0c\n\x05\x04\x02\x02\
    \x03\x06\x12\x03D\x02\x08\n\x0c\n\x05\x04\x02\x02\x03\x01\x12\x03D\t\x1b\
    \n\x0c\n\x05\x04\x02\x02\x03\x03\x12\x03D\x1e\x20\n^\n\x04\x04\x02\x02\
    \x04\x12\x03G\x02\x18\x1aQ\x20Remapping\x20(default\x20is\x20ON)\n\x20Re\
    map\x20subgraphs\x20onto\x20more\x20efficient\x20implementations.\n\n\
    \x0c\n\x05\x04\x02\x02\x04\x06\x12\x03G\x02\x08\n\x0c\n\x05\x04\x02\x02\
    \x04\x01\x12\x03G\t\x12\n\x0c\n\x05\x04\x02\x02\x04\x03\x12\x03G\x15\x17\
    \n\x85\x01\n\x04\x04\x02\x02\x05\x12\x03J\x02*\x1ax\x20Common\x20subgrap\
    h\x20elimination\x20(default\x20is\x20ON)\n\x20e.g.\x20Simplify\x20arith\
    metic\x20ops;\x20merge\x20ops\x20with\x20same\x20value\x20(like\x20const\
    ants).\n\n\x0c\n\x05\x04\x02\x02\x05\x06\x12\x03J\x02\x08\n\x0c\n\x05\
    \x04\x02\x02\x05\x01\x12\x03J\t$\n\x0c\n\x05\x04\x02\x02\x05\x03\x12\x03\
    J')\n\x82\x01\n\x04\x04\x02\x02\x06\x12\x03M\x02%\x1au\x20Arithmetic\x20\
    optimizations\x20(default\x20is\x20ON)\n\x20e.g.\x20Simplify\x20arithmet\
    ic\x20ops;\x20merge\x20ops\x20with\x20same\x20value\x20(like\x20constant\
    s).\n\n\x0c\n\x05\x04\x02\x02\x06\x06\x12\x03M\x02\x08\n\x0c\n\x05\x04\
    \x02\x02\x06\x01\x12\x03M\t\x20\n\x0c\n\x05\x04\x02\x02\x06\x03\x12\x03M\
    #$\n\x8e\x01\n\x04\x04\x02\x02\x07\x12\x03P\x02%\x1a\x80\x01\x20Control\
    \x20dependency\x20optimizations\x20(default\x20is\x20ON).\n\x20Remove\
    \x20redundant\x20control\x20dependencies,\x20which\x20may\x20enable\x20o\
    ther\x20optimization.\n\n\x0c\n\x05\x04\x02\x02\x07\x06\x12\x03P\x02\x08\
    \n\x0c\n\x05\x04\x02\x02\x07\x01\x12\x03P\t\x20\n\x0c\n\x05\x04\x02\x02\
    \x07\x03\x12\x03P#$\n2\n\x04\x04\x02\x02\x08\x12\x03R\x02\x1f\x1a%\x20Lo\
    op\x20optimizations\x20(default\x20is\x20ON).\n\n\x0c\n\x05\x04\x02\x02\
    \x08\x06\x12\x03R\x02\x08\n\x0c\n\x05\x04\x02\x02\x08\x01\x12\x03R\t\x1a\
    \n\x0c\n\x05\x04\x02\x02\x08\x03\x12\x03R\x1d\x1e\n6\n\x04\x04\x02\x02\t\
    \x12\x03T\x02$\x1a)\x20Function\x20optimizations\x20(default\x20is\x20ON\
    ).\n\n\x0c\n\x05\x04\x02\x02\t\x06\x12\x03T\x02\x08\n\x0c\n\x05\x04\x02\
    \x02\t\x01\x12\x03T\t\x1e\n\x0c\n\x05\x04\x02\x02\t\x03\x12\x03T!#\nJ\n\
    \x04\x04\x02\x02\n\x12\x03V\x02\x1d\x1a=\x20Strips\x20debug-related\x20n\
    odes\x20from\x20the\x20graph\x20(off\x20by\x20default).\n\n\x0c\n\x05\
    \x04\x02\x02\n\x06\x12\x03V\x02\x08\n\x0c\n\x05\x04\x02\x02\n\x01\x12\
    \x03V\t\x17\n\x0c\n\x05\x04\x02\x02\n\x03\x12\x03V\x1a\x1c\nC\n\x04\x04\
    \x02\x02\x0b\x12\x03X\x02!\x1a6\x20If\x20true,\x20don't\x20remove\x20unn\
    ecessary\x20ops\x20from\x20the\x20graph\n\n\x0c\n\x05\x04\x02\x02\x0b\
    \x05\x12\x03X\x02\x06\n\x0c\n\x05\x04\x02\x02\x0b\x01\x12\x03X\x07\x1c\n\
    \x0c\n\x05\x04\x02\x02\x0b\x03\x12\x03X\x1f\x20\n\x88\x01\n\x04\x04\x02\
    \x02\x0c\x12\x03[\x02,\x1a{\x20Try\x20to\x20allocate\x20some\x20independ\
    ent\x20Op\x20outputs\x20contiguously\x20in\x20order\x20to\n\x20merge\x20\
    or\x20eliminate\x20downstream\x20Ops\x20(off\x20by\x20default).\n\n\x0c\
    \n\x05\x04\x02\x02\x0c\x06\x12\x03[\x02\x08\n\x0c\n\x05\x04\x02\x02\x0c\
    \x01\x12\x03[\t&\n\x0c\n\x05\x04\x02\x02\x0c\x03\x12\x03[)+\n=\n\x04\x04\
    \x02\x02\r\x12\x03]\x02'\x1a0\x20Force\x20small\x20ops\x20onto\x20the\
    \x20CPU\x20(default\x20is\x20OFF).\n\n\x0c\n\x05\x04\x02\x02\r\x06\x12\
    \x03]\x02\x08\n\x0c\n\x05\x04\x02\x02\r\x01\x12\x03]\t!\n\x0c\n\x05\x04\
    \x02\x02\r\x03\x12\x03]$&\nh\n\x04\x04\x02\x02\x0e\x12\x03`\x02&\x1a[\
    \x20Enable\x20the\x20swap\x20of\x20kernel\x20implementations\x20based\
    \x20on\x20the\x20device\x20placement\n\x20(default\x20is\x20ON).\n\n\x0c\
    \n\x05\x04\x02\x02\x0e\x06\x12\x03`\x02\x08\n\x0c\n\x05\x04\x02\x02\x0e\
    \x01\x12\x03`\t\x20\n\x0c\n\x05\x04\x02\x02\x0e\x03\x12\x03`#%\n\xfc\x01\
    \n\x04\x04\x02\x02\x0f\x12\x03e\x02#\x1a\xee\x01\x20Optimize\x20data\x20\
    types\x20for\x20CUDA\x20(default\x20is\x20OFF).\n\x20This\x20will\x20try\
    \x20to\x20use\x20float16\x20on\x20GPU\x20which\x20is\x20faster.\n\x20Not\
    e\x20that\x20this\x20can\x20change\x20the\x20numerical\x20stability\x20o\
    f\x20the\x20graph\x20and\x20may\n\x20require\x20the\x20use\x20of\x20loss\
    \x20scaling\x20to\x20maintain\x20model\x20convergence.\n\n\x0c\n\x05\x04\
    \x02\x02\x0f\x06\x12\x03e\x02\x08\n\x0c\n\x05\x04\x02\x02\x0f\x01\x12\
    \x03e\t\x1d\n\x0c\n\x05\x04\x02\x02\x0f\x03\x12\x03e\x20\"\n\xb7\x01\n\
    \x04\x04\x02\x02\x10\x12\x03i\x02'\x1a\xa9\x01\x20Optimize\x20data\x20ty\
    pes\x20for\x20MKL\x20(default\x20is\x20OFF).\n\x20This\x20will\x20try\
    \x20to\x20use\x20bfloat16\x20on\x20CPUs,\x20which\x20is\x20faster.\n\x20\
    Note\x20that\x20this\x20can\x20change\x20the\x20numerical\x20stability\
    \x20of\x20the\x20graph.\n\n\x0c\n\x05\x04\x02\x02\x10\x06\x12\x03i\x02\
    \x08\n\x0c\n\x05\x04\x02\x02\x10\x01\x12\x03i\t!\n\x0c\n\x05\x04\x02\x02\
    \x10\x03\x12\x03i$&\nB\n\x04\x04\x02\x02\x11\x12\x03k\x02#\x1a5\x20Disab\
    le\x20the\x20entire\x20meta\x20optimizer\x20(off\x20by\x20default).\n\n\
    \x0c\n\x05\x04\x02\x02\x11\x05\x12\x03k\x02\x06\n\x0c\n\x05\x04\x02\x02\
    \x11\x01\x12\x03k\x07\x1d\n\x0c\n\x05\x04\x02\x02\x11\x03\x12\x03k\x20\"\
    \nb\n\x04\x04\x02\x02\x12\x12\x03o\x023\x1aU\x20Controls\x20how\x20many\
    \x20times\x20we\x20run\x20the\x20optimizers\x20in\x20meta\x20optimizer\
    \x20(default\n\x20is\x20once).\n\n\x0c\n\x05\x04\x02\x02\x12\x06\x12\x03\
    o\x02\x13\n\x0c\n\x05\x04\x02\x02\x12\x01\x12\x03o\x14-\n\x0c\n\x05\x04\
    \x02\x02\x12\x03\x12\x03o02\n\xc8\x01\n\x04\x04\x02\x02\x13\x12\x03u\x02\
    \x1d\x1a\xba\x01\x20The\x20minimum\x20number\x20of\x20nodes\x20in\x20a\
    \x20graph\x20to\x20optimizer.\x20For\x20smaller\x20graphs,\n\x20optimiza\
    tion\x20is\x20skipped.\n\x200\x20means\x20the\x20system\x20picks\x20an\
    \x20appropriate\x20number.\n\x20<\x200\x20means\x20do\x20not\x20skip\x20\
    optimization.\n\n\x0c\n\x05\x04\x02\x02\x13\x05\x12\x03u\x02\x07\n\x0c\n\
    \x05\x04\x02\x02\x13\x01\x12\x03u\x08\x17\n\x0c\n\x05\x04\x02\x02\x13\
    \x03\x12\x03u\x1a\x1c\n\x8b\x01\n\x04\x04\x02\x02\x14\x12\x03y\x02@\x1a~\
    \x20Disable\x20optimizations\x20that\x20assume\x20compressed\x20tensors.\
    \x20Note\x20that\x20this\x20flag\n\x20is\x20experimental\x20and\x20may\
    \x20be\x20removed\x20in\x20the\x20future.\n\n\x0c\n\x05\x04\x02\x02\x14\
    \x05\x12\x03y\x02\x06\n\x0c\n\x05\x04\x02\x02\x14\x01\x12\x03y\x07:\n\
    \x0c\n\x05\x04\x02\x02\x14\x03\x12\x03y=?\n\r\n\x04\x04\x02\x04\x03\x12\
    \x05{\x02\x93\x01\x03\n\x0c\n\x05\x04\x02\x04\x03\x01\x12\x03{\x07\x11\n\
    N\n\x06\x04\x02\x04\x03\x02\0\x12\x03}\x04\x18\x1a?\x20The\x20default\
    \x20setting\x20(SCHEDULING\x20and\x20SWAPPING\x20HEURISTICS\x20only)\n\n\
    \x0e\n\x07\x04\x02\x04\x03\x02\0\x01\x12\x03}\x04\x13\n\x0e\n\x07\x04\
    \x02\x04\x03\x02\0\x02\x12\x03}\x16\x17\n0\n\x06\x04\x02\x04\x03\x02\x01\
    \x12\x03\x7f\x04\x13\x1a!\x20Disabled\x20in\x20the\x20meta-optimizer.\n\
    \n\x0e\n\x07\x04\x02\x04\x03\x02\x01\x01\x12\x03\x7f\x04\x0e\n\x0e\n\x07\
    \x04\x02\x04\x03\x02\x01\x02\x12\x03\x7f\x11\x12\n8\n\x06\x04\x02\x04\
    \x03\x02\x02\x12\x04\x81\x01\x04\x0f\x1a(\x20Driven\x20by\x20manual\x20o\
    p-level\x20annotations.\n\n\x0f\n\x07\x04\x02\x04\x03\x02\x02\x01\x12\
    \x04\x81\x01\x04\n\n\x0f\n\x07\x04\x02\x04\x03\x02\x02\x02\x12\x04\x81\
    \x01\r\x0e\n\xfb\x02\n\x06\x04\x02\x04\x03\x02\x03\x12\x04\x8a\x01\x04\
    \x1c\x1az\x20Swapping\x20heuristic\x20will\x20move\x20a\x20tensor\x20fro\
    m\x20the\x20GPU\x20to\x20the\x20CPU\x20and\x20move\n\x20it\x20back\x20wh\
    en\x20needed\x20to\x20reduce\x20peak\x20memory\x20usage.\n2\xee\x01\x20D\
    riven\x20by\x20heuristics.\x20The\x20behavior\x20of\x20these\x20heuristi\
    cs\x20is\x20subject\x20to\n\x20change.\x20Currently\x20includes\x20an\
    \x20experimental\x20recomputation\x20and\x20swapping\n\x20heuristics.\
    \x20Manual\x20annotations\x20are\x20respected,\x20but\x20additional\x20n\
    odes\x20are\n\x20selected\x20automatically.\n\n\x0f\n\x07\x04\x02\x04\
    \x03\x02\x03\x01\x12\x04\x8a\x01\x04\x17\n\x0f\n\x07\x04\x02\x04\x03\x02\
    \x03\x02\x12\x04\x8a\x01\x1a\x1b\n\x9e\x01\n\x06\x04\x02\x04\x03\x02\x04\
    \x12\x04\x8d\x01\x04!\x1a\x8d\x01\x20Recomputation\x20heuristics\x20will\
    \x20recompute\x20ops\x20(such\x20as\x20Relu\x20activation)\n\x20during\
    \x20backprop\x20instead\x20of\x20storing\x20them,\x20reducing\x20peak\
    \x20memory\x20usage.\n\n\x0f\n\x07\x04\x02\x04\x03\x02\x04\x01\x12\x04\
    \x8d\x01\x04\x1c\n\x0f\n\x07\x04\x02\x04\x03\x02\x04\x02\x12\x04\x8d\x01\
    \x1f\x20\n\x96\x01\n\x06\x04\x02\x04\x03\x02\x05\x12\x04\x90\x01\x04\x1e\
    \x1a\x85\x01\x20Scheduling\x20will\x20split\x20big\x20ops\x20such\x20as\
    \x20AddN\x20and\x20try\x20to\x20enforce\x20a\x20schedule\n\x20of\x20the\
    \x20new\x20computations\x20that\x20decreases\x20peak\x20memory\x20usage.\
    \n\n\x0f\n\x07\x04\x02\x04\x03\x02\x05\x01\x12\x04\x90\x01\x04\x19\n\x0f\
    \n\x07\x04\x02\x04\x03\x02\x05\x02\x12\x04\x90\x01\x1c\x1d\nO\n\x06\x04\
    \x02\x04\x03\x02\x06\x12\x04\x92\x01\x04\x13\x1a?\x20Use\x20any\x20combi\
    nation\x20of\x20swapping\x20and\x20recomputation\x20heuristics.\n\n\x0f\
    \n\x07\x04\x02\x04\x03\x02\x06\x01\x12\x04\x92\x01\x04\x0e\n\x0f\n\x07\
    \x04\x02\x04\x03\x02\x06\x02\x12\x04\x92\x01\x11\x12\n\xac\x01\n\x04\x04\
    \x02\x02\x15\x12\x04\x97\x01\x02%\x1a\x9d\x01\x20Configures\x20memory\
    \x20optimization\x20passes\x20through\x20the\x20meta-optimizer.\x20Has\
    \x20no\n\x20effect\x20on\x20manually\x20requested\x20memory\x20optimizat\
    ion\x20passes\x20in\x20the\x20optimizers\n\x20field.\n\n\r\n\x05\x04\x02\
    \x02\x15\x06\x12\x04\x97\x01\x02\x0c\n\r\n\x05\x04\x02\x02\x15\x01\x12\
    \x04\x97\x01\r\x20\n\r\n\x05\x04\x02\x02\x15\x03\x12\x04\x97\x01#$\n\xc0\
    \x04\n\x04\x04\x02\x02\x16\x12\x04\xa0\x01\x025\x1a\xb1\x04\x20A\x20node\
    \x20name\x20scope\x20for\x20node\x20names\x20which\x20are\x20valid\x20ou\
    tputs\x20of\x20recomputations.\n\x20Inputs\x20to\x20nodes\x20that\x20mat\
    ch\x20this\x20scope\x20may\x20be\x20recomputed\x20(subject\x20either\x20\
    to\n\x20manual\x20annotation\x20of\x20those\x20input\x20nodes\x20or\x20t\
    o\x20manual\x20annotation\x20and\n\x20heuristics\x20depending\x20on\x20m\
    emory_optimization),\x20but\x20the\x20nodes\x20themselves\x20will\n\x20n\
    ot\x20be\x20recomputed.\x20This\x20matches\x20any\x20sub-scopes\x20as\
    \x20well,\x20meaning\x20the\x20scope\n\x20can\x20appear\x20not\x20just\
    \x20as\x20a\x20top-level\x20scope.\x20For\x20example,\x20if\x20the\x20va\
    lue\x20is\n\x20\"gradients/\",\x20the\x20default,\x20it\x20will\x20match\
    \x20node\x20name\x20\"gradients/foo\",\n\x20\"foo/gradients/bar\",\x20bu\
    t\x20not\x20\"foo_gradients/\"\n\n\r\n\x05\x04\x02\x02\x16\x05\x12\x04\
    \xa0\x01\x02\x08\n\r\n\x05\x04\x02\x02\x16\x01\x12\x04\xa0\x01\t0\n\r\n\
    \x05\x04\x02\x02\x16\x03\x12\x04\xa0\x0134\n\xd9\x01\n\x04\x04\x02\x02\
    \x17\x12\x04\xa4\x01\x02'\x1a\xca\x01\x20Maximum\x20number\x20of\x20mill\
    iseconds\x20to\x20spend\x20optimizing\x20a\x20single\x20graph\x20before\
    \n\x20timing\x20out.\x20If\x20equal\x20to\x200\x20the\x20system\x20picks\
    \x20a\x20default\x20(currently\x205\x20minutes).\n\x20If\x20less\x20than\
    \x200\x20the\x20optimizer\x20will\x20never\x20time\x20out.\n\n\r\n\x05\
    \x04\x02\x02\x17\x05\x12\x04\xa4\x01\x02\x07\n\r\n\x05\x04\x02\x02\x17\
    \x01\x12\x04\xa4\x01\x08!\n\r\n\x05\x04\x02\x02\x17\x03\x12\x04\xa4\x01$\
    &\n\x98\x01\n\x04\x04\x02\x02\x18\x12\x04\xa8\x01\x02(\x1a\x89\x01\x20Co\
    nfigures\x20AutoParallel\x20optimization\x20passes\x20either\x20through\
    \x20the\n\x20meta-optimizer\x20or\x20when\x20manually\x20specified\x20th\
    rough\x20the\x20optimizers\x20field.\n\n\r\n\x05\x04\x02\x02\x18\x06\x12\
    \x04\xa8\x01\x02\x15\n\r\n\x05\x04\x02\x02\x18\x01\x12\x04\xa8\x01\x16#\
    \n\r\n\x05\x04\x02\x02\x18\x03\x12\x04\xa8\x01&'\n\xb5\x01\n\x04\x04\x02\
    \x02\x19\x12\x04\xad\x01\x02%\x1a\xa6\x01\x20If\x20true,\x20any\x20optim\
    ization\x20pass\x20failing\x20will\x20cause\x20the\x20MetaOptimizer\x20t\
    o\n\x20stop\x20with\x20an\x20error.\x20By\x20default\x20-\x20or\x20when\
    \x20set\x20to\x20false,\x20failing\x20passes\x20are\n\x20skipped\x20sile\
    ntly.\n\n\r\n\x05\x04\x02\x02\x19\x05\x12\x04\xad\x01\x02\x06\n\r\n\x05\
    \x04\x02\x02\x19\x01\x12\x04\xad\x01\x07\x1f\n\r\n\x05\x04\x02\x02\x19\
    \x03\x12\x04\xad\x01\"$\n\x0c\n\x04\x04\x02\x02\x1a\x12\x04\xaf\x01\x024\
    \n\r\n\x05\x04\x02\x02\x1a\x06\x12\x04\xaf\x01\x02\x18\n\r\n\x05\x04\x02\
    \x02\x1a\x01\x12\x04\xaf\x01\x19.\n\r\n\x05\x04\x02\x02\x1a\x03\x12\x04\
    \xaf\x0113\n\xa3\x05\n\x04\x04\x02\x02\x1b\x12\x04\xbd\x01\x02#\x1a\x94\
    \x05\x20If\x20non-empty,\x20will\x20use\x20this\x20as\x20an\x20alternati\
    ve\x20way\x20to\x20specify\x20a\x20list\x20of\n\x20optimizations\x20to\
    \x20turn\x20on\x20and\x20the\x20order\x20of\x20the\x20optimizations\x20(\
    replacing\x20the\n\x20meta-optimizer).\n\n\x20Of\x20the\x20RewriterConfi\
    g\x20options,\x20only\x20the\x20AutoParallel\x20configuration\x20options\
    \n\x20(the\x20auto_parallel\x20field)\x20apply\x20to\x20manually\x20requ\
    ested\x20optimization\x20passes\n\x20(\"autoparallel\").\x20Memory\x20op\
    timization\x20passes\x20(\"memory\")\x20invoked\x20here\x20are\n\x20not\
    \x20configurable\x20(in\x20contrast\x20to\x20memory\x20optimization\x20p\
    asses\x20through\x20the\n\x20meta-optimizer)\x20and\x20act\x20only\x20on\
    \x20manual\x20op\x20annotations.\n\n\x20Custom\x20optimizers\x20(see\x20\
    custom_optimizers)\x20that\x20are\x20not\x20part\x20of\x20this\n\x20sche\
    dule\x20will\x20be\x20run\x20after\x20-\x20in\x20the\x20order\x20that\
    \x20they\x20were\x20specified.\n\n\r\n\x05\x04\x02\x02\x1b\x04\x12\x04\
    \xbd\x01\x02\n\n\r\n\x05\x04\x02\x02\x1b\x05\x12\x04\xbd\x01\x0b\x11\n\r\
    \n\x05\x04\x02\x02\x1b\x01\x12\x04\xbd\x01\x12\x1c\n\r\n\x05\x04\x02\x02\
    \x1b\x03\x12\x04\xbd\x01\x1f\"\nO\n\x04\x04\x02\x03\0\x12\x06\xc0\x01\
    \x02\xc3\x01\x03\x1a?\x20Message\x20to\x20describe\x20custom\x20graph\
    \x20optimizer\x20and\x20its\x20parameters\n\n\r\n\x05\x04\x02\x03\0\x01\
    \x12\x04\xc0\x01\n\x1e\n\x0e\n\x06\x04\x02\x03\0\x02\0\x12\x04\xc1\x01\
    \x04\x14\n\x0f\n\x07\x04\x02\x03\0\x02\0\x05\x12\x04\xc1\x01\x04\n\n\x0f\
    \n\x07\x04\x02\x03\0\x02\0\x01\x12\x04\xc1\x01\x0b\x0f\n\x0f\n\x07\x04\
    \x02\x03\0\x02\0\x03\x12\x04\xc1\x01\x12\x13\n\x0e\n\x06\x04\x02\x03\0\
    \x02\x01\x12\x04\xc2\x01\x04-\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x06\x12\
    \x04\xc2\x01\x04\x1a\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x01\x12\x04\xc2\
    \x01\x1b(\n\x0f\n\x07\x04\x02\x03\0\x02\x01\x03\x12\x04\xc2\x01+,\n7\n\
    \x04\x04\x02\x02\x1c\x12\x04\xc6\x01\x028\x1a)\x20list\x20of\x20CustomGr\
    aphOptimizers\x20to\x20apply.\n\n\r\n\x05\x04\x02\x02\x1c\x04\x12\x04\
    \xc6\x01\x02\n\n\r\n\x05\x04\x02\x02\x1c\x06\x12\x04\xc6\x01\x0b\x1f\n\r\
    \n\x05\x04\x02\x02\x1c\x01\x12\x04\xc6\x01\x201\n\r\n\x05\x04\x02\x02\
    \x1c\x03\x12\x04\xc6\x0147\nX\n\x04\x04\x02\x02\x1d\x12\x04\xc9\x01\x027\
    \x1aJ\x20VerifierConfig\x20specifying\x20the\x20verifiers\x20to\x20be\
    \x20run\x20after\x20every\x20optimizer.\n\n\r\n\x05\x04\x02\x02\x1d\x06\
    \x12\x04\xc9\x01\x02\x10\n\r\n\x05\x04\x02\x02\x1d\x01\x12\x04\xc9\x01\
    \x110\n\r\n\x05\x04\x02\x02\x1d\x03\x12\x04\xc9\x0136\nm\n\x04\x04\x02\
    \x02\x1e\x12\x04\xcd\x01\x029\x1a_\x20VerifierConfig\x20specifying\x20th\
    e\x20verifiers\x20to\x20be\x20run\x20at\x20the\x20end,\x20after\x20all\n\
    \x20optimizers\x20have\x20run.\n\n\r\n\x05\x04\x02\x02\x1e\x06\x12\x04\
    \xcd\x01\x02\x10\n\r\n\x05\x04\x02\x02\x1e\x01\x12\x04\xcd\x01\x112\n\r\
    \n\x05\x04\x02\x02\x1e\x03\x12\x04\xcd\x0158b\x06proto3\
";

static file_descriptor_proto_lazy: ::protobuf::rt::LazyV2<::protobuf::descriptor::FileDescriptorProto> = ::protobuf::rt::LazyV2::INIT;

fn parse_descriptor_proto() -> ::protobuf::descriptor::FileDescriptorProto {
    ::protobuf::Message::parse_from_bytes(file_descriptor_proto_data).unwrap()
}

pub fn file_descriptor_proto() -> &'static ::protobuf::descriptor::FileDescriptorProto {
    file_descriptor_proto_lazy.get(|| {
        parse_descriptor_proto()
    })
}
